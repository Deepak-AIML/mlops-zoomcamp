{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_data(path:str, filename:str)-> pd.DataFrame:\n",
    "    data = pd.read_parquet(path+filename+'.parquet')\n",
    "    return data\n",
    "\n",
    "# return columns_count\n",
    "def return_columns_count(data:pd.DataFrame, month_name:str)->str:\n",
    "    print(f'No of columns in {month_name} data are ',data.shape[1])\n",
    "\n",
    "def compute_duration(data:pd.DataFrame, from_datetime:str, to_datetime:str)->pd.DataFrame:\n",
    "    data['duration'] = (data[to_datetime] - data[from_datetime]) / pd.Timedelta(minutes=1)\n",
    "    return data\n",
    "\n",
    "def calculate_std_dev(data:pd.DataFrame, col_name:str)->int:\n",
    "    print(f'Standard deviation for column {col_name} is',data[col_name].std())\n",
    "    \n",
    "def execute_question_2(data, from_datetime, to_datetime, col_name):\n",
    "    data = compute_duration(data, from_datetime, to_datetime)\n",
    "    calculate_std_dev(data, col_name)\n",
    "\n",
    "def remove_outliers(data:pd.DataFrame, col_name:str, lower_limit:int, upper_limit:int):\n",
    "    records_before = data.shape[0]\n",
    "    print(records_before)\n",
    "    data = data[(data[col_name]>=lower_limit) & (data[col_name]<=upper_limit)].reset_index()\n",
    "    records_after = data.shape[0]\n",
    "    print(records_after)\n",
    "    print('Percentage of records after removing outliers: ',((records_after)/(records_before))*100)\n",
    "    return data\n",
    "\n",
    "def create_feature_matrix(df: pd.DataFrame, col_1: str, col_2: str):\n",
    "    # Convert the DataFrame to a list of dictionaries\n",
    "    data = df.copy()\n",
    "    data_dict = data[[col_1, col_2]].astype(str).to_dict(orient='records')\n",
    "    \n",
    "    # Create an instance of DictVectorizer\n",
    "    dict_vectorizer = DictVectorizer()\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    feature_matrix = dict_vectorizer.fit_transform(data_dict)\n",
    "    \n",
    "    # Get the feature names\n",
    "    feature_names = dict_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get the dimensionality of the feature matrix\n",
    "    dimensionality = feature_matrix.shape[1]\n",
    "    print(f\"\\nDimensionality of the Feature Matrix: {dimensionality}\")\n",
    "    \n",
    "    return feature_matrix, feature_names, dict_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "jan_data = read_data('/home/deepak/Documents/mlops_zoomcamp/mlops-zoomcamp/data/', 'yellow_tripdata_2023-01') \n",
    "feb_data = read_data('/home/deepak/Documents/mlops_zoomcamp/mlops-zoomcamp/data/', 'yellow_tripdata_2023-02') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1: Read the data for January. How many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of columns in Jan data are  19\n"
     ]
    }
   ],
   "source": [
    "return_columns_count(jan_data, 'Jan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2: What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation for column duration is 42.59435124195458\n"
     ]
    }
   ],
   "source": [
    "execute_question_2(jan_data, 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3: There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive). What fraction of the records left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066766\n",
      "3009173\n",
      "Percentage of records after removing outliers:  98.1220282212598\n"
     ]
    }
   ],
   "source": [
    "jan_data = remove_outliers(jan_data, 'duration', 1, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4: Let's apply one-hot encoding to the pickup and dropoff location IDs. What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix:\n",
      "  (0, 43)\t1.0\n",
      "  (0, 325)\t1.0\n",
      "  (1, 148)\t1.0\n",
      "  (1, 456)\t1.0\n",
      "  (2, 149)\t1.0\n",
      "  (2, 461)\t1.0\n",
      "  (3, 227)\t1.0\n",
      "  (3, 299)\t1.0\n",
      "  (4, 237)\t1.0\n",
      "  (4, 266)\t1.0\n",
      "  (5, 38)\t1.0\n",
      "  (5, 325)\t1.0\n",
      "  (6, 45)\t1.0\n",
      "  (6, 409)\t1.0\n",
      "  (7, 108)\t1.0\n",
      "  (7, 304)\t1.0\n",
      "  (8, 147)\t1.0\n",
      "  (8, 328)\t1.0\n",
      "  (9, 6)\t1.0\n",
      "  (9, 303)\t1.0\n",
      "  (10, 225)\t1.0\n",
      "  (10, 404)\t1.0\n",
      "  (11, 178)\t1.0\n",
      "  (11, 494)\t1.0\n",
      "  (12, 45)\t1.0\n",
      "  :\t:\n",
      "  (3009160, 328)\t1.0\n",
      "  (3009161, 155)\t1.0\n",
      "  (3009161, 494)\t1.0\n",
      "  (3009162, 203)\t1.0\n",
      "  (3009162, 306)\t1.0\n",
      "  (3009163, 50)\t1.0\n",
      "  (3009163, 325)\t1.0\n",
      "  (3009164, 242)\t1.0\n",
      "  (3009164, 401)\t1.0\n",
      "  (3009165, 54)\t1.0\n",
      "  (3009165, 326)\t1.0\n",
      "  (3009166, 64)\t1.0\n",
      "  (3009166, 482)\t1.0\n",
      "  (3009167, 46)\t1.0\n",
      "  (3009167, 401)\t1.0\n",
      "  (3009168, 203)\t1.0\n",
      "  (3009168, 266)\t1.0\n",
      "  (3009169, 233)\t1.0\n",
      "  (3009169, 271)\t1.0\n",
      "  (3009170, 150)\t1.0\n",
      "  (3009170, 273)\t1.0\n",
      "  (3009171, 237)\t1.0\n",
      "  (3009171, 400)\t1.0\n",
      "  (3009172, 45)\t1.0\n",
      "  (3009172, 435)\t1.0\n",
      "\n",
      "Dimensionality of the Feature Matrix: 515\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, feature_names, dict_vectorizer = create_feature_matrix(jan_data, 'PULocationID', 'DOLocationID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5:  Training a model. RMSE on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE on the training data: 7.649261931416412\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable\n",
    "target = jan_data['duration']\n",
    "\n",
    "# Train a plain linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(feature_matrix, target)\n",
    "\n",
    "# Predict on the training data\n",
    "predictions = model.predict(feature_matrix)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, predictions))\n",
    "print(f\"\\nRMSE on the training data: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2913955\n",
      "2855951\n",
      "Percentage of records after removing outliers:  98.00944077722545\n",
      "\n",
      "RMSE on the training data: 7.8118162035401735\n"
     ]
    }
   ],
   "source": [
    "feb_data = compute_duration(feb_data, 'tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "feb_data = remove_outliers(feb_data, 'duration', 1, 60)\n",
    "feb_data_copy = feb_data.copy()\n",
    "test_data_dict = feb_data_copy[['PULocationID', 'DOLocationID']].astype(str).to_dict(orient='records')\n",
    "test_feature_matrix = dict_vectorizer.transform(test_data_dict)\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_feature_matrix)\n",
    "test_target = feb_data['duration']\n",
    "# Calculate the RMSE\n",
    "test_rmse = np.sqrt(mean_squared_error(test_target, test_predictions))\n",
    "print(f\"\\nRMSE on the Test data: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
